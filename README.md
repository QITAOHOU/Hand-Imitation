# Hand-Imitation
This a project for robocamp in which we try to make a robotic arm which would imitate a hand for which feed is given through a webcam

## The TODO
- [X] feed and simulation of a robotic arm - Yash 
- [X] Basic RL Environment building
- [X] Reward function
- [X] Publish the Environment at openAI - Somnath
- [ ] Report Start -Yash 
- [ ] Model Training - Saaswath And Atul
- [ ] Improve The algos
- [ ] Finish Report 

### Sayonara


## Attendance
1. Somnath ([hex-plex](https://github.com/hex-plex))
2. Yash ([numberbee7070](https://github.com/numberbee7070))
3. Saaswath([infini8-13](https://github.com/infini8-13))
4. Atul ([AtuL-KumaR-00](https://github.com/AtuL-KumaR-00))
## Chat
This is our technical chat space if you have a problem link it here someone will take a look
> Atul please start working on Report for now 
> To train now you have to use the RL-Test.py This is after registering
> I have enabled tensorboard to help you see the progress of the training
> Use a VideoCapture(over a directory)
> Dont take the risk of using the live feed as it might take a lot of time or even the hand might not be in the right position
> We would actually train using RL-Train.py but due to some errors its not training well for now i have not updated it as that should not be used

